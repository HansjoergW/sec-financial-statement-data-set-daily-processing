Next
====



- quartal vergleichen
-- Tests results auch in DB ablegen, so dass  Filtern danach einfacher möglich ist
-- saubere Reports pro Stmt Type, überprüfen, ob TagListe wirklich stimmen
-- danach die weiteren Report Typen vergleichen
-- 'Line' Reihenfolge muss noch geprüft werden...

- status index file über https://www.sec.gov/Archives/edgar/monthly/index.json auswerten
  -> File SecIndexIndexJsonParsing.py
  -> man sieht die letzte Bearbeitung
  -> man sieht die letzte Datei

- bessere und klarere Log Statements.. irgendwie standardisieren. Vlt auch so etwas wie eine processstatus am Ende

Later
=====

Ziel: laufendes herunterladen der neuen Reports als XML und bereitstellen der Daten als CSV Datei
- extract evaluate_statement_in als eigener Schritt vor Process
- generation der sub.txt dateien, soweit sinnvoll
- zippen von xml dateien
- Reihenfolge der Spalten in den geparsten CSVs in der selben Reihenfolge wie original, damit es änlicher iwrd
-handhaben von
   3.4. there are some rare cases of statements (4 statements in 5500 reports for q1 2021) that contain multiple root_nodes.
     -> not supported yet. -> idee, zählen der Kinder und den Root mit den meisten children nehmen
     0000829224-21-000029 http://www.starbucks.com/role/DocumentAndEntityInformation
     0000920371-21-000042 http://www.simpsonfg.com/role/ConsolidatedStatementsofStockholdersEquityParenthetical
     0001254699-21-000005 http://www.qvc.com/role/ConsolidatedStatementsofCashFlows
     0001628280-21-002278 http://polaris.com/role/ConsolidatedStatementsOfCashFlows

    BalanceSheet ist als CashFlow angegeben
     0001213900-21-019311 BS: sieht aus als wäre das als CashFlow betitelt, entries deuten aber auf BS hin

    parentheticals cases werden nicht gefunde
        '0001174947-21-000168'
        - xlink:role="http://ruger.com/role/rgr-cbs">
        - xlink:role="http://ruger.com/role/rgr-cbsp">

        '0001178913-21-000696'
        - role="http://solaredge.com/role/sedg-cbs"
        - role="http://solaredge.com/role/sedg-cbsp"

        '0001206774-21-000530'
        - role="http://cassinfo.com/role/cass-cbs1"
        - role="http://cassinfo.com/role/cass-cbsp1"

        '0001553350-21-000261'
        - role="http://lightwavelogic.com/role/lwlg-bs">
        - role="http://lightwavelogic.com/role/lwlg-bsp">


Done
====
31.05.2021 - umbauen dictionaries mit https://realpython.com/python-data-classes/
29.05.2021 - erfolgreich BS und CP parsen, nur noch sehr wenige Ausnahmen
21.05.2021 - erfolgreiches parsen aller reports in q1 2021 ohne überraschungen..
14.05.2021 - diverse optimierungen in pre-parsing
           - neu download mit prüfung auf grösse, da irgendwie die falschen Daten vorhanden sind...
           - donwload-xml Namen mit ADSH, damit eindeutigkeit sicher gestellt ist
13.05.2021 - diverse pre-parsing korrekturen
11.05.2021 - organistaion directory
               -https://docs.python-guide.org/writing/structure/
09.05.2021  - Masstest für teiltestset mit erneutem parsing
            - nur relevante statements parsen
08.05.2021  - line Eintrag aufgrund Hierarchie berechnet
04.05.2021  - alle Daten nochmals durchparsen
03.05.2021  - Fehler prüfen -> "huge text node"
02.05.2021  - Quartal durchparsen -> nur 2 'leere' numfiles können nicht vearbeitet werden
            - Automatisierung des Downloads und aufbereiten der Daten
            -- Die Daten werden laufend nachgeladen und aufbereitet
            -- Pro Report werden die Daten in eigene Dateien in Jahr/Monats/Tag (processingday)
30.04.2021  - pre und num files erzeugen..
            -- erste Version läuft, nächster Schritt komplettes quartal durchparsen
            - IFRS Standard Beispiel finden und prüfen
26.04.2021  - aufteilen code für index und xml files
22.04.2021  - Verwaltung Index Files
             -- bereits abgeschlossene nicht nochmals neuladen -> Status in Progress / finished
             -- finished wird erreicht wenn neues File vorhanden ist
09.04.2021  - Automatisierung des Downloads und aufbereiten der Daten
            -- in die DB soll auch der Name des SecFeedFiles aufgenommen werden, aus welchem die Daten stammen
            -- vor dem Inserten der Daten müssen die Einträge entfernt werden, die bereits vorhanden sind
            --- Spalte mit SecFeedFilenamen füllen
            --- Daten mit Schlüssel SecFeedFile laden und aufgrund adsh bereinigen
09.04.2021  - Sicherstellen, dass das Ergänzen der Informationen funktioniert.
              kleinere Pakete sichern, nicht alles auf einmal
09.04.2021  - Duplicate Check hinzufügen -> sicherstellen, dass jede ADSH nur einmal vorhanden ist.
              Offenbar gibt es mit den März Daten Probleme, entweder doppelt in der Datei, oder aber bereits im Februar vorhanden
05.04.2021  Flywayconfig  und installation