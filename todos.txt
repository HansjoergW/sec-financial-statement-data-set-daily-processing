Next
====

- es gibt bis jetzt rund 84 Files, die nicht gedownloaded werden können.
  die müsste man irgendwie excluden, sonst dauert die Verarbeitung immer wie länger
  Anfrage an Sec webmaster@sec.gov
  - Auflisten der Fälle
  - Prüfen ob die Dinger wirklich nicht auch im Primary Financial Statement Dataset sind
  - 80 Fälle sind allein von letzter Woche (19.07.-23.07.2021)
  - vergleich mit "guten files" aus der gleichen Periode

  => Liste sollte getrackt werden, um zu prüfen, ob die im Nachhinein evtl. korrigiert werden
     -> ist noch entscheidend für das Ergänzen der Daily-Zip Dateien

- beim index file downloaden muss auch so was wie ein loop hin. auch hier kann das downloaden der xbrl-rss files
  mehrmals fehlschlagen und es sollte ein zweiter loop darum gebaut werden.
  -> evtl. verbessert sich hier das ganze durch die Angabe des User-Agent-Header

- line wird in pre als float und nicht als int gespeichert
  -> scheint eher ein problem des ladens zu sein, bzw. es müsste ein konkreter fall untersucht werden
     bei ein paar stichproben sind die linien immer nur als int abgelegt

- daily zip builden -> da muss man aufpassen, wenn im nachhinein neue files hinzugefügt werden...
  also wenn z.B. durch eine spätere Verarbeitung zusätzliche Reports verarbeitet werden konnten
- minimale Metadaten verwaltung für die dailyzips wären nicht schlecht, falls
  später neue files dazukommen, wüsste man, ob man was hinzufügen müsste.
  -> mann könnte auch nur prüfen, ob es das File bereits gibt und falls ja, müsste man neu selektieren

  -> oder man könnte prinzipiell schauen, für welche Tage es Reports ohne dailyzip zugehörigkeit gibt
     und dann könnte man immer erneut selektieren
     -> wäre vermutlich das einfachste

  -> aber dann müsste das Pipeline Projekt tracken, wann eine Datei zum letzten mal geändert wurde.

- es scheint, als schlägt der längenvergleich der gedownloadeten Daten ab und zu fehl (ca. 70 in num only)
  wahrscheinlich aufgrund des enocdings... die frage ist, ob dieser test etwas bringt.
  Ist es wirklich so, oder ist es ein anderes problem

- es kommt auch ab und zu zu sonstinge Excpeptions, die sporadisch auftauchen und dann den Prozess
  "abstürzen lassen".

- saubere, automatische Lösung um ganzes Quartal zu vergleichen. mit vernünftigem Report

- User-Agent für Datendownload muss noch konfigurierbar gemacht werden

Later
=====

- bessere und klarere Log Statements.. irgendwie standardisieren. Vlt auch so etwas wie eine processstatus am Ende

num file
- footnotes sind am Ende in einer eigenen Node -> siehe auch 0000004904-21-000010n
- möglichst alle Infos bis zum Schluss mitnehmen und erst dann finale Version für SEC Zip builden
  -> DDdate auf Ende Datum berechnen, erst wenn die genauste Präzision für ein tag und ein bestimmtes Datum
     gefiltert wurden


Done
====
27.06.2021 - final fixes für kompletten lauf mit daily zip creation
12.06.2021 - Unit Tests für NumParsing umgeschrieben
11.06.2021 - CodeRefactoring für Num umsetzen
           - Reihenfolge testen in Mastest für Pre
31.05.2021 - umbauen dictionaries mit https://realpython.com/python-data-classes/
29.05.2021 - erfolgreich BS und CP parsen, nur noch sehr wenige Ausnahmen
21.05.2021 - erfolgreiches parsen aller reports in q1 2021 ohne überraschungen..
14.05.2021 - diverse optimierungen in pre-parsing
           - neu download mit prüfung auf grösse, da irgendwie die falschen Daten vorhanden sind...
           - donwload-xml Namen mit ADSH, damit eindeutigkeit sicher gestellt ist
13.05.2021 - diverse pre-parsing korrekturen
11.05.2021 - organistaion directory
               -https://docs.python-guide.org/writing/structure/
09.05.2021  - Masstest für teiltestset mit erneutem parsing
            - nur relevante statements parsen
08.05.2021  - line Eintrag aufgrund Hierarchie berechnet
04.05.2021  - alle Daten nochmals durchparsen
03.05.2021  - Fehler prüfen -> "huge text node"
02.05.2021  - Quartal durchparsen -> nur 2 'leere' numfiles können nicht vearbeitet werden
            - Automatisierung des Downloads und aufbereiten der Daten
            -- Die Daten werden laufend nachgeladen und aufbereitet
            -- Pro Report werden die Daten in eigene Dateien in Jahr/Monats/Tag (processingday)
30.04.2021  - pre und num files erzeugen..
            -- erste Version läuft, nächster Schritt komplettes quartal durchparsen
            - IFRS Standard Beispiel finden und prüfen
26.04.2021  - aufteilen code für index und xml files
22.04.2021  - Verwaltung Index Files
             -- bereits abgeschlossene nicht nochmals neuladen -> Status in Progress / finished
             -- finished wird erreicht wenn neues File vorhanden ist
09.04.2021  - Automatisierung des Downloads und aufbereiten der Daten
            -- in die DB soll auch der Name des SecFeedFiles aufgenommen werden, aus welchem die Daten stammen
            -- vor dem Inserten der Daten müssen die Einträge entfernt werden, die bereits vorhanden sind
            --- Spalte mit SecFeedFilenamen füllen
            --- Daten mit Schlüssel SecFeedFile laden und aufgrund adsh bereinigen
09.04.2021  - Sicherstellen, dass das Ergänzen der Informationen funktioniert.
              kleinere Pakete sichern, nicht alles auf einmal
09.04.2021  - Duplicate Check hinzufügen -> sicherstellen, dass jede ADSH nur einmal vorhanden ist.
              Offenbar gibt es mit den März Daten Probleme, entweder doppelt in der Datei, oder aber bereits im Februar vorhanden
05.04.2021  Flywayconfig  und installation