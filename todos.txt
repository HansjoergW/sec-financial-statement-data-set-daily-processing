Next
====

- quartal durchparsen

- quartal vergleichen


- organistaion directory
  -https://docs.python-guide.org/writing/structure/



Later
=====

Ziel: laufendes herunterladen der neuen Reports als XML und bereitstellen der Daten als CSV Datei


- IFRS Standard Beispiel finden und prüfen

- Automatisierung des Downloads und aufbereiten der Daten
-- Die Daten werden laufend nachgeladen und aufbereitet
-- Pro Report werden die Daten in eigene Dateien in Jahr/Monats/Tag (processingDay?) folder geschrieben, evtl. in Zip


- Massentest über ganzes Quartal
-- XML-Dateien für komplettes Quartal downloaden
-- Vergleich mit txt-Daten aus diesem Quartal
--- Alle Reports (10-K/Q) müssen vorhanden sein
--- Die txt-Dateien dürfen keine Zeilen enthalten, die nicht in den XML Daten vorhanden sind
--- Prüfen ob

- status index file über https://www.sec.gov/Archives/edgar/monthly/index.json auswerten
  -> man sieht die letzte Bearbeitung
  -> man sieht die letzte Datei
  -> siehe auch Besondere Fehler

- bessere und klarere Log Statements.. irgendwie standardisieren. Vlt auch so etwas wie eine processstatus am Ende

- zippen von xml dateien


Besondere Fehler
==============
- Wenn am Anfang des Monats das index file noch nicht vorhanden ist (z.B. Fehler am 1. Mai), dann bricht der download
  ab, weil die Datei nicht gefunden werden konnte. (kann auch aufgrund der Zeitverzögerung sein, wurde um 07:10 ausgeführt)
- man könnte auch die index seite parsen -> https://www.sec.gov/Archives/edgar/monthly/index.json
  dann würde man alle vorhandenen Einträge mit ihrer letzten Verarbeitung sehen. So könnte man auch prüfen, welche
  Dateien neu sind und noch nicht verarbeitet worden sind


Done
====
30.04.2021  - pre und num files erzeugen..
            -- erste Version läuft, nächster Schritt komplettes quartal durchparsen
26.04.2021  - aufteilen code für index und xml files
22.04.2021  - Verwaltung Index Files
             -- bereits abgeschlossene nicht nochmals neuladen -> Status in Progress / finished
             -- finished wird erreicht wenn neues File vorhanden ist
09.04.2021  - Automatisierung des Downloads und aufbereiten der Daten
            -- in die DB soll auch der Name des SecFeedFiles aufgenommen werden, aus welchem die Daten stammen
            -- vor dem Inserten der Daten müssen die Einträge entfernt werden, die bereits vorhanden sind
            --- Spalte mit SecFeedFilenamen füllen
            --- Daten mit Schlüssel SecFeedFile laden und aufgrund adsh bereinigen
09.04.2021  - Sicherstellen, dass das Ergänzen der Informationen funktioniert.
              kleinere Pakete sichern, nicht alles auf einmal
09.04.2021  - Duplicate Check hinzufügen -> sicherstellen, dass jede ADSH nur einmal vorhanden ist.
              Offenbar gibt es mit den März Daten Probleme, entweder doppelt in der Datei, oder aber bereits im Februar vorhanden
05.04.2021  Flywayconfig  und installation